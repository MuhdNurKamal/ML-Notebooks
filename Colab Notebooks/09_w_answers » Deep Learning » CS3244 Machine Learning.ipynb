{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"W/ ANSWERS » ARCHIVAL 09 » Deep Learning » CS3244 Machine Learning","provenance":[{"file_id":"19GYOVnXVkgJF7pyaN3C4cVQHZ8xsKC2q","timestamp":1570625294662},{"file_id":"1A2lM8CCe1VgYmcyWUg5Pzj22bf4jT2dI","timestamp":1566305549065},{"file_id":"123n0MI8OtmP0kyMkgMYO3v1p6i5PeT6N","timestamp":1539834565074}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g7ajsT4Wqv32","colab_type":"text"},"source":["$\\color{red}{\\mathrm{Dear\\ Learner,}}$\n","\n","$\\color{red}{\\mathrm{This\\ is\\ the\\ archival\\ version\\  of\\ the\\ original\\ notebook\\ authored\\ at\\ NUS}}$\n","\n","$\\color{red}{\\mathrm{This\\ has\\ been\\ provided\\ to\\ you\\ with\\ programming\\ answers\\ for\\ your\\ individual\\ reference\\ and\\ review }}$\n","\n","$\\color{red}{\\mathrm{Please\\ do\\ not\\ repost\\ to\\ any\\ public\\ sites\\ so\\ that\\ future\\ students\\ can\\ avoid\\ gratuitous\\ copying\\ and\\ can\\ benefit\\ from\\ the\\ challenge\\ of\\ learning}}$\n","\n","Available at http://www.comp.nus.edu.sg/~cs3244/1910/09.colab"]},{"cell_type":"markdown","metadata":{"id":"uvf81x6Vrysn","colab_type":"text"},"source":["![Machine Learning](https://www.comp.nus.edu.sg/~cs3244/1910/img/banner-1910.png)\n","---\n","See **Credits** below for acknowledgements and rights.  For NUS class credit, you'll need to do the corresponding _Assessment_ in [CS3244 in Coursemology](http://coursemology.org/courses/1677) by the respective deadline (as in Coursemology). \n","\n","**You must acknowledge that your submitted Assessment is your independent work, see questions in the Assessment at the end.**\n"]},{"cell_type":"markdown","metadata":{"id":"mUAaknxMYo4I","colab_type":"text"},"source":["**Learning Outcomes for this Week** \n","\n","After watching the videos and completing the exercises for this week, you should be able to:\n","\n","* Explain how CNNs and RNNs works;\n","* Implement basic forms of CNNs and RNNs;\n","* Explain the idea of embeddings and how they can be used to improve performance;\n","* Apply embeddings to sentiment analysis data;\n","* Tune hyperparameters of a CNN;\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rJaPL7rcdSnZ","colab_type":"text"},"source":["_Welcome to the Week $09$ Python notebook._ This week we will learn about **Deep Learning**.  We introduce several _Deep Learning_ architectures in the lecture videos, and will be reviewing this material in the seventh tutorial.\n","\n","In this notebook, we will go through the concept of Convolutional Neural Networks, Recurrent Newural Networks, Embeddings. We will also cover few programming exercise in both pre-tutorial and post-tutorial section of the notebook. We will be using `PyTorch`, to implement these architectures with some interesting datasets."]},{"cell_type":"markdown","metadata":{"id":"Dy5QuHHir65p","colab_type":"text"},"source":["---\n","# Week 09: Pre-Tutorial Work \n","\n","Watch the videos for Week 9 Pre. This week, we will learn about deep neural networks, which are networks of units with more hidden layers, making it more deep and more efficient.\n"]},{"cell_type":"markdown","metadata":{"id":"XxXcd0-CMHaz","colab_type":"text"},"source":["## 1 Basic questions from the videos"]},{"cell_type":"markdown","metadata":{"id":"f4C1wpEfMQG2","colab_type":"text"},"source":["The following are some simple questions you should be able to answer after watching the pre-class videos, notably the video on Convolutional Neural Networks."]},{"cell_type":"markdown","metadata":{"id":"saHYGildhykD","colab_type":"text"},"source":["**Your Turn (Question 1)**: What is the neural network in the **left figure** doing with the weight vectors described?\n","\n","_Choose from: Detecting features of the first row, Detecting features of the first column, Convolution of the features, Analyzing all feature with same weight._"]},{"cell_type":"markdown","metadata":{"id":"dt2WpskLidqV","colab_type":"text"},"source":["**Your Turn (Question 2)**: What is the neural network in the **right figure** doing with the weight vectors described?\n","\n","_Choose from: Detecting features of the first row, Detecting features of the first column, Convolution of the features, Analyzing all feature with same weight._"]},{"cell_type":"markdown","metadata":{"id":"ifDQF3mqKrJV","colab_type":"text"},"source":["\n","<img src=\"https://www.comp.nus.edu.sg/~neamul/Images/9pre01.PNG\" align=\"left\" width = 430/><img src=\"https://www.comp.nus.edu.sg/~neamul/Images/09pre02.PNG\" align=\"right\" width = 430/>"]},{"cell_type":"markdown","metadata":{"id":"gjH1mSkUL94i","colab_type":"text"},"source":["## 2 CNN Coding Example"]},{"cell_type":"markdown","metadata":{"id":"IWb-mnK97_yK","colab_type":"text"},"source":["Now let's do some edge detection using convolutional neural networks!  We will see different kinds of filtering to detect horizontal, vertical or diagonal lines from an image, by using a simple CNN."]},{"cell_type":"markdown","metadata":{"id":"RkoE7agN_RbB","colab_type":"text"},"source":["We will use the `pytorch` library, which we already used in Week 8. Let's first install the necessary libraries."]},{"cell_type":"code","metadata":{"id":"M2HA2LRnjy1f","colab_type":"code","colab":{}},"source":["### Import the pytorch libraries\n","import torch\n","import torchvision\n","import torch.nn as nn\n","\n","!pip install Pillow>=4.1.1\n","\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9qlanqeJ-B3","colab_type":"text"},"source":["Now we will define a convolutional neural network,  a simple one. In the following code block, we define a CNN which has only 1 `input channel`, 1 `output channel` and 3x3 `kernel matrix`."]},{"cell_type":"code","metadata":{"id":"gb_iNYKBC9xA","colab_type":"code","colab":{}},"source":["# Defining a simple CNN with 1 input channel, 1 output channel and kernel matrix size is 3x3.\n","# We use the most simple non-linear activation function here, the ReLU.\n","net = nn.Sequential(nn.Conv2d(1,1,3),nn.ReLU())\n","\n","# Setting the bias value of the network to 0\n","net[0].bias.data = torch.FloatTensor([0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U0FsiSGANXMT","colab_type":"text"},"source":["In the following code block, we define a function which sets the weight vector of our neural network based on the input. For different settings of the weight vector, we obtain different forms of filtering."]},{"cell_type":"code","metadata":{"id":"_PCtMihwJIMB","colab_type":"code","colab":{}},"source":["def edgeDetection(filterType):\n","  \"\"\" \n","    Args:\n","        filterType (int) : type of filter (ranging from 1 to 4)\n","        \n","  \"\"\"\n","   # setting the weight vector of the network to detect horizontal / vertical / diagonal lines\n","  if filterType == 1:\n","    net[0].weight.data = torch.FloatTensor ([[[[-0.5,1.0,-0.5],\n","                                               [-0.5,1.0,-0.5],\n","                                               [-0.5,1.0,-0.5]]]])\n","  elif filterType == 2:\n","    net[0].weight.data = torch.FloatTensor ([[[[-0.5,1.0,1.0],\n","                                               [1.0,-0.5,1.0],\n","                                               [1.0,1.0,-0.5]]]])\n","  elif filterType == 3:\n","    net[0].weight.data = torch.FloatTensor ([[[[ 1.0, 1.0, 1.0],\n","                                               [-0.5,-0.5,-0.5],\n","                                               [-0.5,-0.5,-0.5]]]])\n","  elif filterType == 4:\n","    net[0].weight.data = torch.FloatTensor ([[[[1.0,-0.5,-0.5],\n","                                               [-0.5,1.0,-0.5],\n","                                               [-0.5,-0.5,1.0]]]])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PrcyTAf2OF_T","colab_type":"text"},"source":["In the following code block, we download an image from an URL using the `torchvision` library. Then we display the image. We will use this image to check how the filtering works.\n","\n","Let's check how the original image looks like."]},{"cell_type":"code","metadata":{"id":"ltE0MWM5Z_zE","colab_type":"code","colab":{}},"source":["from PIL import Image\n","# Downloading an image from a given URL using the torchvision library\n","torchvision.datasets.utils.download_url('https://d5wt70d4gnm1t.cloudfront.net/media/a-s/articles/1181-043236208562/close-look-sol-lewitt-900x450-c.jpg',root='data/image',filename=\"Picture.jpg\",md5=\"\")\n","\n","# Opening the image from the uploaded folder\n","k = Image.open('data/image/Picture.jpg').convert('L')\n","\n","# Giving picture credits.  Sol Lewitt was a famous American artist connected with the minimist movement\n","# https://en.wikipedia.org/wiki/Sol_LeWitt\n","print (\"'Detail of A Square Divided Horizontally and Vertically into Four Equal Parts, Each with a Different Direction of Alternating Parallel Bands of Lines', 1982, by Sol Lewitt\")\n","\n","# Showing the original image\n","k"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e6gH5OGsaWz3","colab_type":"text"},"source":["Now we have everything we need. In this code block, we put together all of the code blocks we have written so far in a compact, standalone representation. We first convert the image to a `Tensor`. Finally, we call the `edgeDetection` function with different parameters ranging from $1$ to $4$ to achieve the different filtering types.\n","\n","Let's explore how the filtering works."]},{"cell_type":"code","metadata":{"id":"ag2WBsDCYw3q","colab_type":"code","colab":{}},"source":["\n","# Loading the image as Tensor\n","m = torch.Tensor(np.asarray(k)).view([1,1,450,900])/256\n","\n","#### \n","edgeDetection(1) # change the parameter from 1 to 4 to see different type of filtering\n","####\n","\n","# Filtering the image by passing it to the defined network\n","filteredImage = net(m.round()).detach()\n","\n","# Displaying the image\n","plt.imshow(filteredImage[0,0])\n","\n","# You can use the following code to see the image in a grid\n","#imshow(torchvision.utils.make_grid(net2(m.round()).detach()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vDxTzz51RT3H","colab_type":"text"},"source":["**Your Turn:** Which of the following weight vector corresponds to what kind of edge detectiion (*horizontal / vertical / diagonal*)?\n","\n","* **A:** $\\hspace{10mm}\\begin{bmatrix}\n","    1.0 & 1.0 & 1.0 \\\\\n","    -0.5 & -0.5 & -0.5 \\\\  \n","    -0.5 & -0.5 & -0.5 \n","  \\end{bmatrix}$\n","  \n","* **B:** $\\hspace{10mm}\\begin{bmatrix}\n","    -0.5 & 1.0 & 1.0 \\\\\n","    1.0 & -0.5 & 1.0 \\\\  \n","   1.0 & 1.0 & -0.5 \n","  \\end{bmatrix}$\n","  \n","* **C:** $\\hspace{10mm}\\begin{bmatrix}\n","    1.0 & -0.5 & -0.5\\\\\n","   -0.5 & 1.0 & -0.5 \\\\  \n","   -0.5 &  -0.5 & 1.0 \n","  \\end{bmatrix}$\n","  \n","* **D:** $\\hspace{10mm}\\begin{bmatrix}\n","    -0.5 & 1.0 & -0.5  \\\\\n","   -0.5 & 1.0 & -0.5  \\\\  \n","   -0.5 & 1.0 & -0.5  \n","  \\end{bmatrix}$\n"]},{"cell_type":"markdown","metadata":{"id":"RFR6vZ0Fi_2M","colab_type":"text"},"source":["**Your Turn (Question 3):**  Which is the corresponding weight vector used to detect **Horizontal Line**?\n","\n","_Choose from: A, B, C, D_"]},{"cell_type":"markdown","metadata":{"id":"KKZfGqa-jOK3","colab_type":"text"},"source":["**Your Turn (Question 4):**  Which is the corresponding weight vector used to detect **Vertical Line**?\n","\n","_Choose from: A, B, C, D_"]},{"cell_type":"markdown","metadata":{"id":"-H7aGsKljQ8M","colab_type":"text"},"source":["**Your Turn (Question 5):**  Which is the corresponding weight vector used to detect **Diagonal Line**?\n","\n","_Choose from: A, B, C, D_"]},{"cell_type":"markdown","metadata":{"id":"yYJlb90rkYRg","colab_type":"text"},"source":["## 3 Programming : Recursive Neural Networks (RNNs)"]},{"cell_type":"markdown","metadata":{"id":"Gs6LLwzO_XnQ","colab_type":"text"},"source":["\n","\n","**Classifying names with a character-level RNN**\n","\n","We will be building and training a basic character-level RNN to classify\n","words. A character-level RNN reads words as a series of characters -\n","outputting a prediction and \"hidden state\" at each step, feeding its\n","previous hidden state into each next step. We take the final prediction\n","to be the output, i.e. which class the word belongs to.\n","\n","Specifically, we'll train on a few thousand surnames from 18 languages\n","of origin, and predict which language a name is from based on the\n","spelling:\n","\n","```\n","    (input) Hinton\n","    (-0.47) Scottish\n","    (-1.52) English\n","    (-3.57) Irish\n","\n","    (input) Schmidhuber\n","    (-0.19) German\n","    (-2.48) Czech\n","    (-2.68) Dutch\n","```\n","\n","**Credits**: This section is adapted from one of pytorch's official tutorials, which can be found [here](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)."]},{"cell_type":"markdown","metadata":{"id":"IY9qJTcBNEe-","colab_type":"text"},"source":["### .a Prepare environment and data"]},{"cell_type":"markdown","metadata":{"id":"92NDHokTPYQj","colab_type":"text"},"source":["Let's start by importing the libraries and downloading the data. \n","\n","Run the following cell after restarting your environment and/or copying the notebook. Libraries that we need for the specific section will be loaded at the beginning of each section."]},{"cell_type":"code","metadata":{"id":"LGSnZkYi_uvY","colab_type":"code","colab":{}},"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import glob\n","import os\n","import random\n","import unicodedata\n","import string\n","import time\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Download the required data\n","!wget https://download.pytorch.org/tutorial/data.zip\n","!unzip data.zip"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2N25u7znDZit","colab_type":"text"},"source":["#### Clean and index data\n","The downloaded data are mostly romanized, however, we still need to convert them from Unicode to ASCII.\n","\n","We also need to build the mapping from category (language) to specific names in order to retrieve training samples later.\n","\n","We'll end up with a dictionary of lists of names per language, ```{language: [names ...]}```. "]},{"cell_type":"code","metadata":{"id":"AvDAVXoXGLNk","colab_type":"code","colab":{}},"source":["def findFiles(path): return glob.glob(path)\n","# print(findFiles('data/names/*.txt'))\n","\n","all_letters = string.ascii_letters + \" .,;'\"\n","n_letters = len(all_letters)\n","\n","# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","        and c in all_letters\n","    )\n","\n","# Build the category_names dictionary, a list of names per language\n","category_names = {}  # mapping from category (language) to name\n","all_categories = []  # list of all categories (languages)\n","\n","# Read a file and split into lines\n","def readLines(filename):\n","    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n","    return [unicodeToAscii(line) for line in lines]\n","\n","for filename in findFiles('data/names/*.txt'):\n","    category = os.path.splitext(os.path.basename(filename))[0]\n","    all_categories.append(category)\n","    names = readLines(filename)\n","    category_names[category] = names\n","\n","# number of categories\n","n_categories = len(all_categories)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L1Ec2FC-D5Pg","colab_type":"text"},"source":["#### Turning names into Tensors\n","Now that we have all the names organized, we need to turn them into Tensors to make any use of them.\n","\n","To represent a single letter, we use a \"one-hot vector\" of size <1 x n_letters>. \n","\n","A one-hot vector is filled with 0s except for a 1 at index of the current letter, e.g. \"b\" = <0 1 0 0 0 ...>. \n","\n","To make a word we join a bunch of those into a 2D matrix <name_length x 1 x n_letters>.\n","\n","That extra 1 dimension is because PyTorch assumes everything is in batches - we're just using a batch size of 1 here."]},{"cell_type":"code","metadata":{"id":"-zFK6FAREe-u","colab_type":"code","colab":{}},"source":["# Find letter index from all_letters, e.g. \"a\" = 0\n","def letterToIndex(letter):\n","    return all_letters.find(letter)\n","\n","# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n","def letterToTensor(letter):\n","    tensor = torch.zeros(1, n_letters)\n","    tensor[0][letterToIndex(letter)] = 1\n","    return tensor\n","\n","# Turn a name into a <name_length x 1 x n_letters>,\n","# or an array of one-hot letter vectors\n","def nameToTensor(name):\n","    tensor = torch.zeros(len(name), 1, n_letters)\n","    for li, letter in enumerate(name):\n","        tensor[li][0][letterToIndex(letter)] = 1\n","    return tensor\n","\n","# This is just an example. You can change to something else and see what happens!\n","print(letterToTensor('J'))\n","print(nameToTensor('Jones').size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ksdqi52DffFN","colab_type":"text"},"source":["### .b Creating the network"]},{"cell_type":"markdown","metadata":{"id":"IsIdoRxUHZcH","colab_type":"text"},"source":["\n","You can implement an RNN in a very \"pure\" way, as regular feed-forward layers like Linear or Conv.\n","\n","The RNN we use here is just 2 linear layers which operate on an input and hidden state, with a LogSoftmax layer after the output.\n","\n"," <div align=\"center\">\n","<img src=\"https://www.comp.nus.edu.sg/~neamul/Images/CS3244_1910/rnn_archi.png\"  width = 450/>\n","<p>  A Simple Recurrent Neural Network. \n","</div>\n","\n"," (Diagram Credit: From [https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6](https://miro.medium.com/max/726/1*XxxiA0jJvPrHEJHD4z893g.png))"]},{"cell_type":"code","metadata":{"id":"mFTMBaWtFPYd","colab_type":"code","colab":{}},"source":["class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(RNN, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","\n","        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n","        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        combined = torch.cat((input, hidden), 1)\n","        hidden = self.i2h(combined)\n","        output = self.i2o(combined)\n","        output = self.softmax(output)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        # hidden states are 0 at the beginning\n","        return torch.zeros(1, self.hidden_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EBrj_gXDFnA_","colab_type":"text"},"source":["To create an instance of this network we need to specify:\n","\n","- `n_letters` : number of all possible letters.\n","- `n_hidden` : number of hidden units and hidden state size.\n","- `n_categories` : number of categories. In our case it is 18.\n","\n","We can now create our RNN as follows:"]},{"cell_type":"code","metadata":{"id":"ulX4v3GwGtpW","colab_type":"code","colab":{}},"source":["rnn = RNN(input_size=n_letters, hidden_size=128, output_size=n_categories)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mSYFrVt1FiS1","colab_type":"text"},"source":["To run a step of this network we need to pass an input (in our case, the Tensor for the current letter) and a previous hidden state (which we initialize as zeros at first). We'll get back the output (probability of each language) and a next hidden state (which we keep for the next step)."]},{"cell_type":"code","metadata":{"id":"39Gux-GBJNrb","colab_type":"code","colab":{}},"source":["# Try the following code. You can try different names.\n","input = nameToTensor('Albert')\n","hidden = torch.zeros(1, 128)\n","\n","output, next_hidden = rnn(input[0], hidden)\n","print(output)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7H-y04TzIDhm","colab_type":"text"},"source":["### .c Train the network"]},{"cell_type":"markdown","metadata":{"id":"VGrPKnP2IQBq","colab_type":"text"},"source":["#### Prepare for training\n","Before going into training we should make a few helper functions. The\n","first is to interpret the output of the network, which we know to be a\n","likelihood of each category. We can use ``Tensor.topk`` to get the index\n","of the greatest value. We will also want a quick way to get a training example (a name and its language):"]},{"cell_type":"code","metadata":{"id":"9zZ-Q8c5IRc_","colab_type":"code","colab":{}},"source":["def categoryFromOutput(output):\n","    top_n, top_i = output.topk(1)\n","    category_i = top_i[0].item()\n","    return all_categories[category_i], category_i\n","\n","def randomChoice(l):\n","    return l[random.randint(0, len(l) - 1)]\n","\n","def randomTrainingExample():\n","    category = randomChoice(all_categories)\n","    name = randomChoice(category_names[category])\n","    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n","    name_tensor = nameToTensor(name)\n","    return category, name, category_tensor, name_tensor\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bi0KvCuqI1R-","colab_type":"text"},"source":["Finally, let's setup the train and evaluation engine."]},{"cell_type":"markdown","metadata":{"id":"-okVBBM4mDwy","colab_type":"text"},"source":["**Your Turn (Question 6)** We removed some codes from `train_rnn()`. Please complete these two functions. The question marks in the template are placeholders for python statements."]},{"cell_type":"code","metadata":{"id":"L-5raPKlI6Mr","colab_type":"code","colab":{}},"source":["def train_rnn(category_tensor, name_tensor, loss_function, optimizer):\n","    hidden = rnn.initHidden()\n","\n","    optimizer.zero_grad()\n","\n","    ####### Your Turn ########\n","    #\n","    # We removed some code here, now it's your turn to make it run.\n","    # Consider the following template:\n","    #\n","    # for ? in range(?):\n","    #    output, hidden = rnn(?, ?)\n","    \n","    for i in range(name_tensor.size()[0]):\n","        output, hidden = rnn(name_tensor[i], hidden)\n","        \n","    #########################\n","\n","    loss = loss_function(output, category_tensor)\n","    loss.backward()\n","    optimizer.step()\n","\n","    return output, loss.item()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YSAM2mGImP8z","colab_type":"text"},"source":["**Your Turn (Question 7)** We removed some codes from `evaluate_rnn()`. Please complete these two functions. The question marks in the template are placeholders for python statements."]},{"cell_type":"code","metadata":{"id":"VXJZcgorlrDx","colab_type":"code","colab":{}},"source":["def evaluate_rnn(name_tensor):\n","    hidden = rnn.initHidden()\n","\n","    ####### Your Turn ########\n","    #\n","    # We removed some code here, now it's your turn to make it run.\n","    # Consider the following template:\n","    #\n","    # for ? in range(?):\n","    #    output, hidden = rnn(?, ?)\n","    \n","    for i in range(name_tensor.size()[0]):\n","        output, hidden = rnn(name_tensor[i], hidden)\n","        \n","    #########################\n","\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nj2-B4suJfNm","colab_type":"text"},"source":["#### Now let's train it\n","Now we just have to run that with a bunch of examples. Since the\n","``train`` function returns both the output and loss we can print its\n","guesses and also keep track of loss for plotting. Since there are 1000s\n","of examples we print only every ``print_every`` examples, and take an\n","average of the loss."]},{"cell_type":"code","metadata":{"id":"2QMqhukdJlat","colab_type":"code","colab":{}},"source":["# Hyperparameters\n","learning_rate = 0.005\n","n_iters       = 100000\n","print_every   = 5000\n","plot_every    = 1000\n","loss_function = nn.NLLLoss()\n","optimizer     = torch.optim.SGD(rnn.parameters(), learning_rate)\n","\n","# Keep track of losses for plotting\n","current_loss = 0\n","all_losses = []\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","start = time.time()\n","\n","for i in range(1, n_iters + 1):\n","    category, line, category_tensor, line_tensor = randomTrainingExample()\n","    output, loss = train_rnn(category_tensor, line_tensor, loss_function, optimizer)\n","    current_loss += loss\n","\n","    # Print iter number, loss, name and guess\n","    if i % print_every == 0:\n","        guess, guess_i = categoryFromOutput(output)\n","        correct = '✓' if guess == category else '✗ (%s)' % category\n","        print('%d %d%% (%s) %.4f %s / %s %s' % (i, i / n_iters * 100, timeSince(start), loss, line, guess, correct))\n","\n","    # Add current loss avg to list of losses\n","    if i % plot_every == 0:\n","        all_losses.append(current_loss / plot_every)\n","        current_loss = 0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nlI9JeEVLxzj","colab_type":"text"},"source":["### .d Evaluate the network\n","To see how well the network performs on different categories, we will\n","create a confusion matrix, indicating for every actual language (rows)\n","which language the network guesses (columns). To calculate the confusion\n","matrix a bunch of samples are run through the network with\n","``evaluate_rnn()``, which is the same as ``train_rnn()`` minus the backprop."]},{"cell_type":"code","metadata":{"id":"7ODXCXQbMlcF","colab_type":"code","colab":{}},"source":["# Keep track of correct guesses in a confusion matrix\n","confusion = torch.zeros(n_categories, n_categories)\n","n_confusion = 5000\n","\n","# Go through a bunch of examples and record which are correctly guessed\n","for i in range(n_confusion):\n","    category, line, category_tensor, line_tensor = randomTrainingExample()\n","    output = evaluate_rnn(line_tensor)\n","    guess, guess_i = categoryFromOutput(output)\n","    category_i = all_categories.index(category)\n","    confusion[category_i][guess_i] += 1\n","\n","# Normalize by dividing every row by its sum\n","for i in range(n_categories):\n","    confusion[i] = confusion[i] / confusion[i].sum()\n","\n","fig, ax = plt.subplots(figsize=(12,12))\n","sns.heatmap(confusion, xticklabels=all_categories, yticklabels=all_categories, ax=ax)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PoljxiSAn8bo","colab_type":"text"},"source":["**Your Turn (Question 8)**: Why are certain pairs of countries more easily confuse our RNN than other pairs?\n","\n","_Replace with your answer: For example: because they have similar character combinations (contexts) in their surnames._"]},{"cell_type":"markdown","metadata":{"id":"MikWpnb9NlDp","colab_type":"text"},"source":["You can also evaluate this RNN using your own input:\n"]},{"cell_type":"code","metadata":{"id":"bUgRxfJ_NrwS","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Try your own input. Type your name and run the code! (Double click the title to reveal the code. This is not a question!)\n","custom_input = \"Xu\" #@param {type:\"string\"}\n","def predict(input_name, n_predictions=3):\n","    print('\\n> %s' % input_name)\n","    with torch.no_grad():\n","        output = evaluate_rnn(nameToTensor(input_name))\n","\n","        # Get top N categories\n","        topv, topi = output.topk(n_predictions, 1, True)\n","        predictions = []\n","\n","        for i in range(n_predictions):\n","            value = topv[0][i].item()\n","            category_index = topi[0][i].item()\n","            print('(%.2f) %s' % (value, all_categories[category_index]))\n","            predictions.append([value, all_categories[category_index]])\n","\n","\n","predict(custom_input)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GFZOPTcl-Ubg","colab_type":"text"},"source":["---\n","# Week 09: Post-Tutorial Work\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"j8QJDAn2p0X0","colab_type":"text"},"source":["## 4 Embeddings"]},{"cell_type":"markdown","metadata":{"id":"KyksK5U6_a-Z","colab_type":"text"},"source":["\n","\n","In this part, we'll learn a new concept called **embeddings**. We will use *movie review* string data to create a sparse feature vector and then implement a *sentiment-analysis* model using that feature vector. To get a better understanding of *embeddings* and why it is used, we will first implement a linear model and later use a DNN model with and without using an embedding. Then we will visualize and try to see how embeddings help.\n","\n","**Credits:** This section of the exercises is adapted from the [Google Tutorial on Embeddings](https://colab.research.google.com/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb), licensed under [Apache License version 2.0](https://www.apache.org/licenses/LICENSE-2.0)"]},{"cell_type":"markdown","metadata":{"id":"zyzyh99kQtUx","colab_type":"text"},"source":["### .a Building a Sentiment Analysis Model \n","\n","Let's train a sentiment-analysis model on this data that predicts if a review is generally *favorable* (label of 1) or *unfavorable* (label of 0).\n","\n","To do so, we'll turn our string-value `terms` into feature vectors by using a *vocabulary*, a list of each term we expect to see in our data. For the purposes of this exercise, we've created a small vocabulary that focuses on a limited set of terms. Most of these terms were found to be strongly indicative of *favorable* or *unfavorable*, but some were just added because they're interesting.\n","\n","Each term in the vocabulary is mapped to a coordinate in our feature vector. To convert the string-value `terms` for an example into this vector format, we encode such that each coordinate gets a value of 0 if the vocabulary term does not appear in the example string, and a value of 1 if it does. Terms in an example that don't appear in the vocabulary are thrown away."]},{"cell_type":"markdown","metadata":{"id":"95MlBZzURQUG","colab_type":"text"},"source":["**Note:** *We can use a larger vocabulary, and there are special tools for creating these. In addition, instead of just dropping terms that are not in the vocabulary, we can introduce a small number of OOV (out-of-vocabulary) buckets, which you can hash to terms not in the vocabulary. We can also use a __feature hashing__ approach that hashes each term, instead of creating an explicit vocabulary. This works well in practice, but loses interpretability, which we want to retain for this exercise.*"]},{"cell_type":"markdown","metadata":{"id":"FNshptyEPFio","colab_type":"text"},"source":["Before start, let's do some setup. We start by importing the libraries that we need for all sections. \n","\n","Run this cell after restarting your environment and or copying the notebook. Libraries that we need for the specific section will be loaded at the beginning of each section.\n","\n","Next, we will define our `train` function, which we already used last week. We will use it multiple times in this section."]},{"cell_type":"code","metadata":{"id":"5GDqvFOIPA9D","colab_type":"code","colab":{}},"source":["### Load the pytorch libraries\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","\n","# Load the other neccesary libraries\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vueTa91MPDDX","colab_type":"code","colab":{}},"source":["def train(model, trainloader, validationloader, lossfunction, optimizer, n_epochs=100, verbose=True):\n","  \"\"\"\n","    Args:\n","        model (pytorch neural network): the network we want to train\n","        trainloader (data loader): The data loader for the training set\n","        validationloader (data loader): The data loader for the validation set\n","        lossfunction (a pytorch loss function): The loss function used to train the network\n","        optimizer (a pytorch optimizer ): The optimizer used to train the network\n","        n_epochs (int): The number of epochs the network is trained\n","    Returns:\n","        trainingLosses,validationLosses (Lists of floats): returns the losses of each epoch\n","  \"\"\"\n","  trainingLosses, validationLosses = [],[]\n","  for t in range(n_epochs):\n","    model = model.train()\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader):\n","      inputs, labels = data\n","      inputs, labels = Variable(inputs), Variable(labels) # See the comments from last week\n","      inputs =  inputs.cuda()\n","      labels = labels.cuda()\n","      optimizer.zero_grad() # See the comments from last week\n","      outputs = model(inputs) # See the comments from last week\n","    #   ipdb.set_trace()\n","      loss = lossfunction(outputs, labels) # Compute the loss\n","      loss.backward() # Compute the gradient for each variable\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n","      optimizer.step() # Update the weights according to the computed gradient\n","            \n","      # for printing\n","      running_loss += loss.data.item()\n","    # The second loop is actually not training, it's just calculating the loss in the validation set\n","    # Otherwise, it's the same as above\n","    model = model.eval()\n","    with torch.no_grad():\n","        running_loss_val = 0.0\n","        for i, data in enumerate(validationloader):\n","            inputs, labels = data\n","            inputs, labels = Variable(inputs), Variable(labels).long()\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","            outputs = model(inputs) # problematic for students\n","            loss = lossfunction(outputs, labels) # Compute the loss\n","            \n","            # for printing\n","            running_loss_val += loss.data.item()\n","        trainingLosses.append(running_loss)\n","        validationLosses.append(running_loss_val)\n","    if verbose:\n","        print(\"Epoch: {} Training loss: {:f} Validation loss: {:f}\".format(t+1,running_loss,running_loss_val))\n","#   return trainingLosses,validationLosses"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p8zPo-kGRcKX","colab_type":"text"},"source":["### .b Building the Input Pipeline"]},{"cell_type":"markdown","metadata":{"id":"Kk-efxPaR5ml","colab_type":"text"},"source":["We converted the data set from the original Tenserflow to simple lists and then [pickled](https://wiki.python.org/moin/UsingPickle) them. You can download it with the following code. This might take a few minutes. "]},{"cell_type":"code","metadata":{"id":"0uU1lJYLznN3","colab_type":"code","colab":{}},"source":[" # This line will clone a git repository with the data and save it into the files of this notebook.\n"," # You'll only need to run this code once (per reset of the runtime); it will throw errors afterwards.\n","\n","! git clone --recursive https://github.com/MartinStrobel/CS3244Week09data.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSX2dGAKhG8f","colab_type":"code","colab":{}},"source":["import pickle\n","statements = pickle.load( open(\"CS3244Week09data/Week09_embeddings_statements.p\",'rb'))\n","labels = pickle.load( open(\"CS3244Week09data/Week09_embeddings_labels.p\",'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jNt_p5-kScux","colab_type":"text"},"source":["After downloading the dataset, we can look at a few statements. Let's see how one looks:\n"]},{"cell_type":"code","metadata":{"id":"TdXQVrRiF_6B","colab_type":"code","colab":{}},"source":["print(' '.join(statements[11])) # Why 11?"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bcrheLeNSy6O","colab_type":"text"},"source":["Now we need to transform the statements into a usable data set. Let's start very simply and focus only on whether 50 informative terms occur within the statements (as opposed to the 171,476 words in the [Oxford English Dictionary](https://en.oxforddictionaries.com/explore/how-many-words-are-there-in-the-english-language/).) "]},{"cell_type":"code","metadata":{"id":"Ii2k1haCSrwO","colab_type":"code","colab":{}},"source":["# 50 informative terms that compose our model vocabulary \n","informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n","                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n","                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n","                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n","                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n","                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n","                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n","                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n","                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n","                     \"drama\", \"family\")\n","# This is just a crude way of assigning emotions to the above words from bad (-1), over neutral (0) to good.\n","# We will use that for plotting later\n","informative_terms_emotion = [-1,1,1,-1,1,1,1,-1,-1,-1,-1,0,1,1,-1,-1,1,1,-1,1,1,1,-1,1\n","                             ,1,0,-1,0,1,1,-1,1,-1,-1,-1,-1,0,0,0,1,0,0,0,0,0,0,0,0,0,0]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QnVGA1EAJaIb","colab_type":"code","colab":{}},"source":["def convertStatmentToVector(statement, informative_terms=informative_terms):\n","  \"\"\"\n","    Args:\n","        statement (string) : the statement we want to convert to vector\n","        informative_terms (list of string) : the list of informative keywords that we want to find\n","    Returns:\n","        tensor (pytorch tensor) : pytorch tensor converted from the statement \n","  \"\"\"\n","  tensor = torch.zeros(len(informative_terms))\n","  for term in statement:\n","    if term in informative_terms:\n","        tensor[informative_terms.index(term)] = 1\n","  return tensor"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j45tCAg-POqF","colab_type":"text"},"source":["Let's split our data into 20,000 training points and 5,000 validation points. The data is already shuffled, so we can just split it. We have done this many times before, so it should be familiar to you."]},{"cell_type":"code","metadata":{"id":"rdMW2Ix3JAnT","colab_type":"code","colab":{}},"source":["# This takes a couple of seconds\n","# For labels, we squeeze dimension 1 to make labels in shape (N,). \n","X_train = torch.zeros([20000, len(informative_terms)], dtype=torch.float)\n","y_train = torch.tensor(np.asarray(labels)[:20000,None], dtype=torch.float).squeeze(1).long()\n","X_val   = torch.zeros([5000, len(informative_terms)], dtype=torch.float)\n","y_val   = torch.tensor(np.asarray(labels)[20000:,None], dtype=torch.float).squeeze(1).long()\n","\n","# Loop to convert every training statement to a vector\n","for i,statement in enumerate(statements[:20000]):\n","  X_train[i] = convertStatmentToVector(statement)\n","\n","# Loop to convert every validation statement to a vector\n","for i,statement in enumerate(statements[20000:]):\n","  X_val[i] = convertStatmentToVector(statement)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VuYS0WBoL272","colab_type":"text"},"source":["Now that we have transformed our data into tensors we can create our data loaders:"]},{"cell_type":"code","metadata":{"id":"A3B2MTQQMGtZ","colab_type":"code","colab":{}},"source":["sentimentTrainloader      = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train,y_train), batch_size=20000)\n","sentimentValidationloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_val,y_val), batch_size=20000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6zDNKmI1TJSS","colab_type":"text"},"source":["Next we define the loss function. This time we are using **nn.NLLLoss()**. This loss function is wildly used with log_softmax activation for multi-class (k >= 2) classification. You are encouraged to read documentation about [LogSoftmax](https://pytorch.org/docs/stable/nn.html#logsoftmax) and [NLLLoss](https://pytorch.org/docs/stable/nn.html#nllloss)."]},{"cell_type":"code","metadata":{"id":"-xJxOoCRV9OT","colab_type":"code","colab":{}},"source":["embeddingLoss = nn.NLLLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xm8C1lYrvqII","colab_type":"code","colab":{}},"source":["def accuracy(model,dataloader):\n","  \"\"\"\n","    Args:\n","        model (pytorch model) : the model we want to analyze\n","        dataloader (pytorch dataloader): the dataloader to load corresponding \n","          dataset for that model like training or validation set\n","    Returns:\n","        accu (float) : the calculated accuracy of the model on the provided data\n","  \"\"\"\n","  model = model.eval()\n","  with torch.no_grad():\n","    correct = 0.0;\n","    total = 0.0;\n","    for i, data in enumerate(dataloader):\n","        inputs, labels = data\n","        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n","        outputs = model(inputs)\n","        correct += (labels == outputs.argmax(dim=1)).sum().item()\n","        total += len(labels)\n","    accu = correct/total    \n","  return accu"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WcK-57e6TUjY","colab_type":"text"},"source":["### .c Use a Linear Model with Sparse Inputs and an Explicit Vocabulary\n","\n","For our first model, we'll build a Linear classifier using the 50 informative terms; always start simple (and the iterate)!\n","\n","We use a different optimizer Adagrad this time. It's one of the many improvements of SGD. We could get similar results with SGD, but Adagrad converges a faster and is more consistent, so it's better suited for this exercise. You can read more about Adagrad as well as many other optimization algorithms [here](http://ruder.io/optimizing-gradient-descent/index.html#adagrad)."]},{"cell_type":"code","metadata":{"id":"FfuLJyOFTUDJ","colab_type":"code","colab":{}},"source":["linearNet = nn.Sequential(\n","    nn.Linear(len(informative_terms), 2),\n","    nn.LogSoftmax(dim=1)\n",").cuda()\n","\n","linearOpt = optim.Adagrad(linearNet.parameters(), 1e-1)\n","# You may also try SGD for fun after you've finished this task\n","# linearOpt = optim.SGD(linearNet.parameters(), 1e-1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8EdUlX_L25NN","colab_type":"text"},"source":["Now we will train our linear classifier using the defined optimizer:"]},{"cell_type":"code","metadata":{"id":"w92UlpBwQl0v","colab_type":"code","colab":{}},"source":["train(linearNet,sentimentTrainloader,sentimentValidationloader,embeddingLoss,linearOpt,verbose=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cwSeafO2xXs0","colab_type":"text"},"source":["Let's see what accuracy we get:"]},{"cell_type":"code","metadata":{"id":"HWOzva8QxVts","colab_type":"code","colab":{}},"source":["accuracy(linearNet,sentimentValidationloader)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uRz39lYksXPR","colab_type":"text"},"source":["### .d Use a DNN with Sparse Inputs and an Explicit Vocabulary\n","\n","We have seen in the previous section how a linear model performs. Now we  will try a DNN on the same data. Let's see if we can do better or not. We will declare a DNN, slightly more complex than before and an optimizer for the network."]},{"cell_type":"code","metadata":{"id":"lJ2ZBhlpsZQp","colab_type":"code","colab":{}},"source":["DNNNet = nn.Sequential(\n","    nn.Linear(len(informative_terms), 100),\n","    nn.ReLU(),\n","    nn.Dropout(),\n","    nn.Linear(100, 2),\n","    nn.LogSoftmax(dim=1)\n",").cuda()\n","\n","# The optimizer for DNNNet\n","DNNOpt = optim.Adagrad(DNNNet.parameters(), 1e-1, weight_decay=1e-4)\n","# DNNOpt = optim.SGD(DNNNet.parameters(), 1e-1, momentum=0.9, weight_decay=1e-3)\n","\n","# Train our DNNNet with the optimizer\n","train(DNNNet,sentimentTrainloader,sentimentValidationloader,embeddingLoss,DNNOpt,n_epochs=100,verbose=True);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jvb4fOsQxlC0","colab_type":"text"},"source":["Let's see what accuracy we get this time:"]},{"cell_type":"code","metadata":{"id":"FETxi8zrxkkN","colab_type":"code","colab":{}},"source":["accuracy(DNNNet,sentimentValidationloader)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uKzScsmNt6yV","colab_type":"text"},"source":["### .e Use an Embedding with a DNN Model\n","\n","From *Linear* to *DNN*, we have seen some improvement on  accuracy. We will now try DNN with an embedding layer. Let's see if we can do better than DNN.\n","\n","In this task, we'll implement our DNN model using an embedding layer. An embedding layer takes a sparse vector or an index as input and returns a dense vector as output. \n","\n","Please note that its behavior is library-dependent and there are no \"standard\" implementation. For example, pytorch's embedding layer takes indices instead of sparse vectors as input. \n","\n","You are encouraged to read documentations about [Embedding](https://pytorch.org/docs/stable/nn.html#embedding) layer."]},{"cell_type":"markdown","metadata":{"id":"sBtvMslN8D6l","colab_type":"text"},"source":["First, we need to convert our one-hot representation into indices. Note that since the inputs are indices, it should be LongTensor instead of FloatTensor. "]},{"cell_type":"code","metadata":{"id":"jZjjfC9i7K80","colab_type":"code","colab":{}},"source":["# We need an index to indicate \"not presenting\". Since we use 0~(vocab_size-1) \n","# as indices for vocab_size vocabularies, vocab_size itself can be used as the \n","# index for \"not presenting\"\n","\n","def terms_to_indices(X, vocab_size):\n","    X_new = np.zeros([X.shape[0], vocab_size])\n","    for i, x in enumerate(X):\n","        X_new[i, :] = [ j if xi !=0 else vocab_size for j, xi in enumerate(x) ]\n","    return X_new\n","# Note the tailing underscore\n","X_train_ = torch.LongTensor(terms_to_indices(X_train, len(informative_terms)))\n","X_val_ = torch.LongTensor(terms_to_indices(X_val, len(informative_terms)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"snW6tHUw2EbD","colab_type":"code","colab":{}},"source":["embeddingTrainloader      = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train_,y_train), batch_size=20000)\n","embeddingValidationloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_val_,y_val), batch_size=5000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yPj4lCvxx1m9","colab_type":"text"},"source":["Now let's try the embedding layer. There are many ways of designing the network, let's use the most naive way. We will retrieve embeddings based on the input informative terms, and use the mean of all the retrieved embeddings as the feature of the document. Finally, we will use a linear classifier to perform sentiment analysis."]},{"cell_type":"code","metadata":{"id":"J7tql-9S5iDk","colab_type":"code","colab":{}},"source":["class EmbeddingNet(nn.Module):\n","\n","    def __init__(self, vocab_size, embedding_dim):\n","        super(EmbeddingNet, self).__init__()\n","        \n","        # These are two constants we need to transform the output \n","        self.embedding_dim = embedding_dim\n","        self.vocab_size = vocab_size\n","        \n","        # An embedding layer is basically a lookup table the input is a vector with indices \n","        # and the output is their represenation in a embedding space\n","        self.embeddings = nn.Embedding(vocab_size+1, embedding_dim, padding_idx=vocab_size)\n","        self.linear1 = nn.Linear(embedding_dim, 2)\n","\n","    def forward(self, inputs):\n","        embeds = self.embeddings(inputs)\n","        out = torch.log_softmax(self.linear1(embeds.mean(dim=1)),dim=1)\n","\n","        return out\n","      \n","############ Your Turn: Edit this code block later ####################      \n","embeddingNet = EmbeddingNet(50,2).cuda()\n","## first parameter indicates the size of the informative_terms\n","## second parameter indicates the dimension\n","###############################################################"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"anxv3PMg9EJO","colab_type":"text"},"source":["We will now declare the `optimizer` for our embedding network. Then train the network."]},{"cell_type":"code","metadata":{"id":"plP9lj6SuH-S","colab_type":"code","colab":{}},"source":["######### You may need to re-run this block later to answer Q02-Q04 ########\n","embeddingOpt = optim.Adagrad(embeddingNet.parameters(), 1e-1)\n","train(embeddingNet,embeddingTrainloader,embeddingValidationloader,embeddingLoss,embeddingOpt,n_epochs=200,verbose=True);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3HzxlGQI9Rqf","colab_type":"text"},"source":["Let's see... How well do we do on accuracy now that we use embeddings?"]},{"cell_type":"code","metadata":{"id":"89zx81AjzcQs","colab_type":"code","colab":{}},"source":["accuracy(embeddingNet,embeddingValidationloader)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QkMmp47lzx8o","colab_type":"text"},"source":["### .f Examine the Embedding\n","\n","Let's now take a look at the actual embedding space, and visualize where the terms end up in it."]},{"cell_type":"markdown","metadata":{"id":"_Qr99eKi9oGo","colab_type":"text"},"source":["We will first visualize the keywords. Run the code below and then try to answer the following question."]},{"cell_type":"markdown","metadata":{"id":"AwU9Rl4m3dB5","colab_type":"text"},"source":["**Your Turn (Question 1):** Which of the following describes the output?\n","\n","_Choose from: Similar words are clustered together, Most of the similar words are close to each other with some exception, Most of the words that are close are not correlated at all_"]},{"cell_type":"code","metadata":{"id":"04QxK7s9084b","colab_type":"code","colab":{}},"source":["colors = {-1:\"red\", 0:\"black\", 1:\"green\" }\n","with torch.no_grad():\n","    for term_index in range(len(informative_terms)):\n","        # the embedding layer takes indices, instead of one-hot vectors, as inputs\n","        embedding_xy = embeddingNet.embeddings(torch.LongTensor([term_index]).cuda())\n","        plt.text(embedding_xy[0][0],\n","            embedding_xy[0][1],\n","            informative_terms[term_index], color=colors[informative_terms_emotion[term_index]])\n","\n","# Do a little setup to make sure the plot displays nicely.  \n","# H/T Always do good when presenting.\n","plt.rcParams[\"figure.figsize\"] = (15, 15)\n","embedding_matrix = embeddingNet.embeddings.weight.detach().cpu().numpy()\n","plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n","plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())\n","plt.show() "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Op1XpqQe-vv4","colab_type":"text"},"source":["**Your Turn:** You have seen the output by running it once. Now retrain the `EmbeddingEmbeddingNet` model and run the above code block again. Then answer the following question."]},{"cell_type":"markdown","metadata":{"id":"uR-vF_0e4AOB","colab_type":"text"},"source":["**Your Turn (Question 2):** How the output looks like after retraining the model?\n","\n","_Choose from: It looks the same as before, It looks better than previous one, It looks worse than the previous one._"]},{"cell_type":"markdown","metadata":{"id":"Z9oYsQaU_rOx","colab_type":"text"},"source":["In this task, you need to retrain the `embeddingNet` model again, but this time with only **10 epochs**.  Change the code accordingly, then train the model, generate the graph and answer the following question."]},{"cell_type":"markdown","metadata":{"id":"K-yBDO-D4Znl","colab_type":"text"},"source":["**Your Turn (Question 3):** How does the output looks like after retraining the model with only 10 epoch?\n","\n","_Choose from: It looks the same as before, It looks better than previous one, It looks worse than the previous one._"]},{"cell_type":"markdown","metadata":{"id":"PfkM8CYT4ld_","colab_type":"text"},"source":["**Your Turn (Question 4):** Explain the reason for your answer of Q03.\n","\n","_Replace with your answer_"]},{"cell_type":"markdown","metadata":{"id":"iulTvC0A6HzZ","colab_type":"text"},"source":["## 5 Image Classification with CNN"]},{"cell_type":"markdown","metadata":{"id":"PIFSLUKHDXK3","colab_type":"text"},"source":["\n","\n","Next, we will implement CNN using PyTorch. We start by installing Pytorch and importing the libaries. We copied the code here so that you can start the post-class notebook with ou running the code above.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gJbdtf5ZK3Kz","colab":{}},"source":["### Load the pytorch libraries\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","\n","# Load the other neccesary libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qC8qbXz0Lv_z","colab_type":"text"},"source":["### .a Gathering and Loading Data\n","\n","As with most Machine Learning projects, a minority of the code you end up writing has to do with actual statistics––most is spent on gathering, cleaning, and readying your data for analysis. CNNs in Pytorch are no exception.\n","\n","Pytorch ships with the `torchvision` package, which makes it easy to download and use datasets for CNNs. To stick with convention and benchmark accurately, we’ll use the **CIFAR-10 dataset**. CIFAR-10 contains images of 10 different classes, and is a standard library of sorts used for CNN building. \n","\n","The first step to get our data is to use Pytorch and download it. This may take a few minites to finish. \n","\n"]},{"cell_type":"code","metadata":{"id":"O87Y7l0a_Z56","colab_type":"code","colab":{}},"source":["## The compose function allows for multiple transforms\n","#\n","# transforms.ToTensor() converts our PILImage to a tensor of shape (C x H x W) in the range [0,1]\n","# transforms.Normalize(mean,std) normalizes a tensor to a (mean, std) for (R, G, B)\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","train_set = torchvision.datasets.CIFAR10(root='./cifardata', train=True, download=True, transform=transform)\n","\n","test_set = torchvision.datasets.CIFAR10(root='./cifardata', train=False, download=True, transform=transform)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3VfAef02M1j2","colab_type":"text"},"source":["We then designate the 10 possible labels for each image:"]},{"cell_type":"code","metadata":{"id":"WHXA8zMn7ZEH","colab_type":"code","colab":{}},"source":["classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F3M8SSxKM6KS","colab_type":"text"},"source":["The final step of data preparation is to define **data samplers** for our images. Data samplers are a very useful tool in PyTorch that helps us to split all of the available training examples into training, test, and cross validation sets when we train our model later on. "]},{"cell_type":"code","metadata":{"id":"le7vKLvI3f7q","colab_type":"code","colab":{}},"source":["from torch.utils.data.sampler import SubsetRandomSampler\n","\n","# Training\n","n_training_samples = 20000\n","train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n","\n","# Validation\n","n_val_samples = 5000\n","val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n","\n","# Test\n","n_test_samples = 5000\n","test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-c6BWziYXRyJ","colab_type":"text"},"source":["OK, now let us visualize some of the data samples in the CIFAR-10 dataset by running the following code:"]},{"cell_type":"code","metadata":{"id":"TFDGQRdqXdmA","colab_type":"code","colab":{}},"source":["# functions to show an image\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","# get some random training images\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, sampler=train_sampler)\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xkZZhJTCNUXZ","colab_type":"text"},"source":["### .b Designing a Neural Net in Pytorch\n","\n","Pytorch makes it pretty easy to implement all of those key components that we described above. We’ll be making use of 4 major functions in our CNN class: \n","\n"," - `torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)` – applies convolution\n","\n","- `torch.nn.relu(x)` – applies ReLU\n","\n","- `torch.nn.MaxPool2d(kernel_size, stride, padding)` – applies Max Pooling\n","\n","- `torch.nn.Linear(in_features, out_features)` – fully connected layer (multiply inputs by learned weights)\n","\n","Now as we already get all components at hand, let's begin to write our CNN code in Pytorch. We’ll create a `SimpleCNN` class which inherits from the master `torch.nn.Module` class. \n","\n"]},{"cell_type":"code","metadata":{"id":"xLOBAB6tOXcw","colab_type":"code","colab":{}},"source":["from torch.autograd import Variable\n","import torch.nn.functional as F\n","\n","class SimpleCNN(torch.nn.Module):\n","    \n","    # Our batch shape for input x is (3, 32, 32)\n","    \n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        \n","        # Input channels = 3, output channels = 18\n","        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n","        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        \n","        # 4608 input features, 64 output features (see sizing flow below)\n","        self.fc1 = torch.nn.Linear(18 * 16 * 16, 64)\n","        \n","        # 64 input features, 10 output features for our 10 defined classes\n","        self.fc2 = torch.nn.Linear(64, 10)\n","        \n","    def forward(self, x):\n","        \n","        # Computes the activation of the first convolution\n","        # Size changes from (3, 32, 32) to (18, 32, 32)\n","        x = F.relu(self.conv1(x))\n","        \n","        # Size changes from (18, 32, 32) to (18, 16, 16)\n","        x = self.pool(x)\n","        \n","        # Reshape data to input to the input layer of the neural net\n","        # Size changes from (18, 16, 16) to (1, 4608)\n","        # Recall that the -1 infers this dimension from the other given dimension\n","        x = x.view(-1, 18 * 16 *16)\n","        \n","        # Computes the activation of the first fully connected layer\n","        # Size changes from (1, 4608) to (1, 64)\n","        x = F.relu(self.fc1(x))\n","        \n","        # Computes the second fully connected layer (activation applied later)\n","        # Size changes from (1, 64) to (1, 10)\n","        x = self.fc2(x)\n","        return(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvKs9RcjOh1y","colab_type":"text"},"source":["Let’s explain what’s going on here. We’re creating a `SimpleCNN` class with one class method: `forward`. The `forward()` method computes a forward pass of the CNN, which includes the four steps we outlined above. When an instance of the SimpleCNN class is created, we define internal functions to represent the layers of the net. During the forward pass we call these internal functions.\n","\n","One of the pesky parts about manually defining neural nets is that we need to specify the sizes of inputs and outputs at each part of the process. The comments should give some direction as to what’s happening with size changes at each step. \n","\n","You can see that in the above codes, the input dimension is **(3, 32, 32)**, which means our input image has $3$ input channels, and each channel has a resolution of $32 \\times 32$. The number of output channels is set to $18$, meaning that we have $18$ different kernels, and the `kernel size` is set to $3$, which means the size of each kernel is $3\\times 3$. And for the convolution operation, we set `stride = 1` and `padding = 1`. Under this setting, we get an output tensor with shape **(18, 32, 32)** after the convolution.  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"BCPikbwM48qS","colab_type":"text"},"source":["**Your Turn (Question 5):** What is the output dimension after convolution if we change the input dimention to $(6, 16, 16)$, with other settings remaining the same?\n","\n","_CHoose from: $(6,16,16), (6,15,15), (18,16,16), (18,15,15)$_"]},{"cell_type":"markdown","metadata":{"id":"FVOYj-1aTkZd","colab_type":"text"},"source":["After the convolution, we send the output tensor (shape is **(18, 32, 32)**) to a max pooling layer, in which the parameters are set to: `kernel_size = 2`, `stride = 2`, and `padding = 0`. This results in a tensor with shape **(18, 16, 16)**. "]},{"cell_type":"markdown","metadata":{"id":"k0DeueUZ5aEy","colab_type":"text"},"source":["**Your Turn (Question 6):** What is the output dimension after max pooling from input $(18,32,32)$ if we change the kernel size to $4$, and stride to $4$, with other settings remaining the same?\n","\n","_Choose from: $(9,8,8), (9,4,4), (18,8,8), (18,4,4)$_"]},{"cell_type":"markdown","metadata":{"id":"5qelBKtk5rqU","colab_type":"text"},"source":["### .c Training our CNN in Pytorch"]},{"cell_type":"markdown","metadata":{"id":"io4_T-pyVUq8","colab_type":"text"},"source":["\n","\n","Once we’ve defined the class for our CNN, we need to train the net itself. This is where neural network code gets interesting. If you’re working with more basic types of machine learning algorithms, you can usually get meaningful output in just a few lines of code. But with neural networks in Pytorch (and TensorFlow) though, it takes a bunch more code than that. Our basic flow is **a training loop**: each time we pass through the loop (called and “epoch”), we compute a forward pass on the network and implement backpropagation to adjust the weights. We’ll also record some other measurements like loss and time passed, so that we can analyze them as the net trains itself. \n","\n","To start, we’ll define our **data loaders** using the samplers we created above.\n"]},{"cell_type":"code","metadata":{"id":"tHZx8vP5V6Oq","colab_type":"code","colab":{}},"source":["# DataLoader takes in a dataset and a sampler for loading (num_workers deals with system level memory) \n","def get_train_loader(batch_size):\n","    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n","                                           sampler=train_sampler, num_workers=2)\n","    return(train_loader)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLkoY6CbWFah","colab_type":"code","colab":{}},"source":["# Test and validation loaders have constant batch sizes, so we can define them directly\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, sampler=test_sampler, num_workers=2)\n","val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler, num_workers=2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31rZxay7WIC3","colab_type":"text"},"source":["We’ll also define our loss and optimizer functions that the CNN will use to find the right weights. We’ll be using **Cross Entropy Loss (Log Loss)** as our loss function, which strongly penalizes high confidence in the wrong answer. The optimizer is the popular **Adam** algorithm. "]},{"cell_type":"code","metadata":{"id":"cjXypkzUWVkJ","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","def createLossAndOptimizer(net, learning_rate=0.001):\n","    \n","    #Loss function\n","    loss = torch.nn.CrossEntropyLoss()\n","    \n","    #Optimizer\n","    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","    \n","    return(loss, optimizer)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wq0BbfvSWY8T","colab_type":"text"},"source":["Finally, we’ll define a function to train our CNN using a simple for loop. "]},{"cell_type":"code","metadata":{"id":"IQ4Gx2n4WdFG","colab_type":"code","colab":{}},"source":["import time\n","\n","def trainNet(net, batch_size, n_epochs, learning_rate):\n","    \n","    #Print all of the hyperparameters of the training iteration:\n","    print(\"===== HYPERPARAMETERS =====\")\n","    print(\"batch_size=\", batch_size)\n","    print(\"epochs=\", n_epochs)\n","    print(\"learning_rate=\", learning_rate)\n","    print(\"=\" * 30)\n","    \n","    #Get training data\n","    train_loader = get_train_loader(batch_size)\n","    n_batches = len(train_loader)\n","    \n","    # Create our loss and optimizer functions\n","    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n","    \n","    # Time for printing\n","    training_start_time = time.time()\n","    \n","    # Loop for n_epochs\n","    for epoch in range(n_epochs):\n","        \n","        running_loss = 0.0\n","        print_every = n_batches // 10\n","        start_time = time.time()\n","        total_train_loss = 0\n","        \n","        for i, data in enumerate(train_loader, 0):\n","            \n","            # Get inputs\n","            inputs, labels = data\n","            \n","            # Set the parameter gradients to zero\n","            optimizer.zero_grad()\n","            \n","            # Forward pass, backward pass, optimize\n","            outputs = net(inputs)\n","            loss_size = loss(outputs, labels)\n","            loss_size.backward()\n","            optimizer.step()\n","            \n","            #Print statistics\n","            running_loss += loss_size.item()\n","            total_train_loss += loss_size.item()\n","            \n","            # Print every 10th batch of an epoch\n","            if (i + 1) % (print_every + 1) == 0:\n","                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n","                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n","                # Reset running loss and time\n","                running_loss = 0.0\n","                start_time = time.time()\n","            \n","        # At the end of the epoch, do a pass on the validation set\n","        total_val_loss = 0\n","        for inputs, labels in val_loader:\n","            \n","            # Forward pass\n","            val_outputs = net(inputs)\n","            val_loss_size = loss(val_outputs, labels)\n","            total_val_loss += val_loss_size.item()\n","            \n","        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n","        \n","    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z6ZxiHc-WlYv","colab_type":"text"},"source":["During each epoch of training, we pass data to the model **in batches** whose size we define when we call the training loop. Data is feature engineered using the SimpleCNN class we’ve defined, and then basic metrics are printed after a few passes. During each loop, we also calculate the loss on our validation set. \n","\n","To actually train the net now only requires two lines of code: "]},{"cell_type":"code","metadata":{"id":"SO37ApQvWyQg","colab_type":"code","colab":{}},"source":["CNN = SimpleCNN()\n","trainNet(CNN, batch_size=32, n_epochs=5, learning_rate=0.001)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bbKm4_RQaJh4","colab_type":"text"},"source":["### .d Evaluation \n","\n","After the training, now let's see if our CNN works by evaluating the classfication accuracy in the test data:"]},{"cell_type":"code","metadata":{"id":"3DH5odBTaK_D","colab_type":"code","colab":{}},"source":["correct = 0\n","total = 0\n","for data in test_loader:\n","    images, labels = data\n","    outputs = CNN(images)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum()\n","\n","print('Accuracy of the network on the test images: %f %%' % (100 * float(correct) / total))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y29V5EfRbUIZ","colab_type":"text"},"source":["OK, maybe you were expecting a better classification accuracy. This is exactly the work for you to do. Please try to tune the network structure or hyper-parameters of the simple CNN in order to get a better classification accuracy. We know that tuning the neural network is the least interesting thing you want to do, because it's boring and annoying. But this is what you, as a beginner, have to do and is also a good way to help you understand CNN better. \n","\n","After you finish, please record your best accuracy achieved and its corresponding network and parameter settings. "]},{"cell_type":"markdown","metadata":{"id":"Bq1axw5X5uVR","colab_type":"text"},"source":["**Your Turn (Question 7):** What is the best classification accuracy you achieved?\n","\n","_Replace with your answer_"]},{"cell_type":"markdown","metadata":{"id":"v51rk0hr54hp","colab_type":"text"},"source":["**Your Turn (Question 8):**  Please describe the network structure and parameter settings for your best experiment.\n","\n","_Replace with your answer_"]},{"cell_type":"markdown","metadata":{"id":"hZX4JTdyIRuQ","colab_type":"text"},"source":["---\n","## 6 Readings - for better understanding\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YcZG_v1e1Dli","colab_type":"text"},"source":["In this notebook, we will learn about what is Convolutional Neural Network (CNN), and how to implement a CNN in PyTorch. \n","\n","As there are lots of great CNN tutorials on the Internet, we don't need to write a fresh version again. For most contents of this post-class notebook, we are re-using a tutorial from the blog post: [https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/](https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/), which is very good for beginners to learn CNN using PyTorch; and we highly recommend it.  We modified some parts to add more detailed explanations and some exercises for you. \n","\n","Ok, Let's get started.  "]},{"cell_type":"markdown","metadata":{"id":"62mOp7_e3g0G","colab_type":"text"},"source":["### What is a Convolutional Neural Network (CNNs)?\n","\n","Convolutional Neural Networks (ConvNets or CNNs) are a category of neural networks that have proven very effective in areas such as image recognition and classification. ConvNets have been successful in identifying faces, objects and traffic signs apart from powering vision in robots and self driving cars. \n","\n","I think you already learned how CNN works after watching the post-class videos. So here I just do a quick recap of the key components in CNN:\n","\n","- Convolutional Layer\n","- ReLU Layer\n","- Max Pooling\n","- Fully Connected Layers\n","\n","If you are still confused about some of the above concepts, don't worry!  We recommend you to go through the Stanford CS231n lecture notes, which is widely considered as one of the best CNN tutorials by the community. The link is as follows:   \n","\n","[http://cs231n.github.io/convolutional-networks/](http://cs231n.github.io/convolutional-networks/)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JshEZjAx6X0y","colab_type":"text"},"source":["#### .a Convolution Layer"]},{"cell_type":"markdown","metadata":{"id":"G7P7QAC77Zwh","colab_type":"text"},"source":["\n","\n","The CNN gets its name from the process of convolution. Think of convolution as applying a **filter** to our image. We pass over a mini image, usually called a kernel, and output the resulting filtered subset of our image.\n","\n","<div align=\"center\">\n","<img src=\"http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif\" width=400>\n","<p> Figure 1. The convolution operation. </p>\n","</div>\n","\n","(Diagram credit:  [https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch](https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch))\n","\n","Since an image is just a bunch of pixel values, in practice this means multiplying small parts of our input images by the filter. There are a few parameters that get adjusted here: \n","\n"," - **Kernel Size** – the size of the filter.\n"," - **Kernel Type** – the values of the actual filter. Some examples include *identity*, *edge detection*, and *sharpen*.\n"," - **Stride** – the rate at which the kernel passes over the input image. A stride of 2 moves the kernel in 2 pixel increments.\n"," - **Padding** – we can add layers of 0s to the outside of the image in order to make sure that the kernel properly passes over the edges of the image.\n"," - **Output Layers** – how many different kernels are applied to the image.\n","\n","The output of the convolution process is called the “convolved feature” or “feature map.” Remember: it’s just a filtered version of our original image where we multiplied some pixels by some numbers.\n","\n","The resulting feature map can be viewed as a more optimal representation of the input image that’s more informative to the eventual neural network that the image will be passed through. In practice, convolution combined with the next two steps has been shown to greatly increase the accuracy of neural networks on images.\n","\n","You’ll see the convolution step through the use of the `torch.nn.Conv2d()` function in Pytorch."]},{"cell_type":"markdown","metadata":{"id":"WYxUkNPm6Z85","colab_type":"text"},"source":["#### .b ReLU"]},{"cell_type":"markdown","metadata":{"id":"R2GAqvRX_ay9","colab_type":"text"},"source":["\n","\n","Since the convolution operation is essentially a linear function; in CNN, we also need to add in a nonlinear function to help approximate non-linear relationship in the underlying data. \n","\n","The function most popular with CNNs is the ReLU function and it’s extremely simple. We already introduced ReLU to you in the Week 8 post-class notebook. Here for a quick recap, I give the formula of the ReLU function again, which is simply converts all negative pixel values to $0$. \n","\n","$$\n","R(z) = \\max(0, z)\n","$$\n","\n","And we also put the same Figure in Week 8 again to help you see the difference between Sigmoid and ReLU function. \n","\n","<div align=\"center\">\n","<img src=\"https://miro.medium.com/max/1452/1*XxxiA0jJvPrHEJHD4z893g.png\" width=400>\n","<p> Figure 2. The Sigmoid and ReLU Function.  </p>\n","</div>\n","\n"," (Diagram Credit: From [https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6))\n","\n","There are other functions that can be used to add non-linearity, like *tanh* or *softmax*. But in CNNs, ReLU is the most commonly used.\n","\n","You’ll see the ReLU step through the use of the `torch.nn.relu()` function in Pytorch. "]},{"cell_type":"markdown","metadata":{"id":"tZQlnEDU6cQ3","colab_type":"text"},"source":["#### .c Max Pooling"]},{"cell_type":"markdown","metadata":{"id":"buGmvyb4Brko","colab_type":"text"},"source":["\n","\n","Another important part in CNNs is pooling, and the name describes it pretty well: we pass over sections of our image and pool them into the highest value in the section. Depending on the size of the pool, this can greatly reduce the size of the feature set that we pass into the neural network. This graphic from Stanford’s course page visualizes it simply: \n","\n","<div align=\"center\">\n","<img src=\"https://blog.algorithmia.com/wp-content/uploads/2018/03/word-image-5.png\" width=400>\n","<p> Figure 3. The max pooling operation.  </p>\n","</div>\n","\n"," (Diagram Credit: From [https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/](https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/))\n"," \n","Max pooling also has a few of the same parameters as convolution that can be adjusted, like **stride** and **padding**. There are also other types of pooling that can be applied, like **sum pooling** or **average pooling**.\n","\n","You’ll see the Max Pooling step through the use of the `torch.nn.MaxPool2d()` function in Pytorch. "]},{"cell_type":"markdown","metadata":{"id":"Mpp3Sc7U6fSP","colab_type":"text"},"source":["#### .d Fully Connected Layers"]},{"cell_type":"markdown","metadata":{"id":"xQsO0FXfC5rD","colab_type":"text"},"source":["\n","\n","After the above steps are applied (convolution, ReLU, and max-pooling), the resulting image is passed into the traditional neural network architecture. Designing the optimal neural network is beyond the scope of this notebook, and we’ll be using a simple 2 layer format with one hidden layer and one output layer. \n","\n","This part of the CNN is almost identical to any other standard neural network. The key to understanding CNNs is this: the driver of better accuracy is the steps we take to engineer better features, not the classifier we end up passing those values through. Convolution, ReLU, and max pooling prepare our data for the neural network in a way that extracts all the useful information they have in an efficient manner. \n","\n","You’ll see the forward pass step through the use of the `torch.nn.Linear()` function in Pytorch."]},{"cell_type":"markdown","metadata":{"id":"-kGaO2wXmyVP","colab_type":"text"},"source":["---\n","# Credits\n","Authored by Martin Strobel, Xu Ziwei, [Liangming Pan](https://www.liangmingpan.com), [Min-Yen Kan](http://www.comp.nus.edu.sg/~kanmy) (2019), affiliated with [WING](http://wing.comp.nus.edu.sg), [NUS School of Computing](http://www.comp.nus.edu.sg) and [ALSET](http://www.nus.edu.sg/alset).\n","Licensed as: [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/ ) (CC BY 4.0).\n","Please retain and add to this credits cell if using this material as a whole or in part.\n"]}]}